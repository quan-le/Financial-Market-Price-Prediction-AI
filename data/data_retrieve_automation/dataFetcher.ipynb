{
 "cells": [
  {
   "cell_type": "code",
   "id": "22610872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T01:47:33.018598Z",
     "start_time": "2026-01-03T01:47:33.007917Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "4f7e2bcc",
   "metadata": {},
   "source": [
    "## Fetching Price from alphavantage API"
   ]
  },
  {
   "cell_type": "code",
   "id": "bef532d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T01:47:33.037516Z",
     "start_time": "2026-01-03T01:47:33.026986Z"
    }
   },
   "source": [
    "# data/alphavantage.py\n",
    "RAW_DIR = \"../raw\"\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "\n",
    "class AlphaVantagePriceFetcher:\n",
    "    \"\"\"\n",
    "    Fetch daily OHLCV data for stocks, FX, crypto, or commodities.\n",
    "    Priority:\n",
    "      1. Local CSV if exists\n",
    "      2. Alpha Vantage (if API key available)\n",
    "      3. yfinance fallback\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "    def __init__(self, api_key_env=\"ALPHAVANTAGE_API_KEY\"):\n",
    "        self.api_key = os.environ.get(api_key_env, None)\n",
    "        \n",
    "    def _load_local_csv(self, symbol):\n",
    "        csv_path = f\"{RAW_DIR}/{symbol}.csv\"\n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path, parse_dates=[\"date\"])\n",
    "            return df\n",
    "        return None\n",
    "    \n",
    "    def _save_csv(self, df: pd.DataFrame, symbol: str):\n",
    "        df.to_csv(f\"{RAW_DIR}/{symbol}.csv\", index=False)\n",
    "    \n",
    "    def _fetch_alpha_vantage(self, symbol: str, asset_type: str):\n",
    "        \"\"\"\n",
    "        asset_type: stock, fx, crypto, commodity\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            return None\n",
    "        function_map = {\n",
    "            \"stock\": \"TIME_SERIES_DAILY_ADJUSTED\",\n",
    "            \"fx\": \"FX_DAILY\",\n",
    "            \"crypto\": \"DIGITAL_CURRENCY_DAILY\",\n",
    "            \"commodity\": \"TIME_SERIES_DAILY\"\n",
    "        }\n",
    "\n",
    "        params = {\n",
    "            \"apikey\": self.api_key,\n",
    "            \"function\": function_map.get(asset_type, \"TIME_SERIES_DAILY_ADJUSTED\"),\n",
    "            \"symbol\": symbol,\n",
    "            \"outputsize\": \"full\",\n",
    "            \"datatype\": \"json\"\n",
    "        }\n",
    "        \n",
    "        # FX pairs require special params\n",
    "        if asset_type == \"fx\":\n",
    "            if \"/\" in symbol:\n",
    "                from_sym, to_sym = symbol.split(\"/\")\n",
    "            else:\n",
    "                from_sym, to_sym = symbol[:3], symbol[3:]\n",
    "            params[\"from_symbol\"] = from_sym\n",
    "            params[\"to_symbol\"] = to_sym\n",
    "            params.pop(\"symbol\")\n",
    "        # Crypto requires special params\n",
    "        if asset_type == \"crypto\":\n",
    "            params[\"market\"] = \"USD\"\n",
    "        # Retry with exponential backoff for rate limits\n",
    "        for retry in range(5):\n",
    "            r = requests.get(self.BASE_URL, params=params)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                print(data)\n",
    "                if \"Error Message\" in data or \"Note\" in data:\n",
    "                    # Probably rate limited or symbol invalid\n",
    "                    time.sleep(2 ** retry)\n",
    "                    continue\n",
    "                return data\n",
    "            time.sleep(2 ** retry)\n",
    "        return None   \n",
    "    def _parse_alpha_vantage(self, data: dict, symbol: str, asset_type: str):\n",
    "        \"\"\"\n",
    "        Turns AlphaVantage JSON into standardized OHLCV DataFrame.\n",
    "        \"\"\"\n",
    "        key_map = {\n",
    "            \"stock\": \"Time Series (Daily)\",\n",
    "            \"commodity\": \"Time Series (Daily)\",\n",
    "            \"fx\": \"Time Series FX (Daily)\",\n",
    "            \"crypto\": \"Time Series (Digital Currency Daily)\"\n",
    "        }\n",
    "        key = key_map.get(asset_type, \"Time Series (Daily)\")\n",
    "        if key not in data:\n",
    "            return None\n",
    "\n",
    "        raw = data[key]\n",
    "        records = []\n",
    "        for date_str, vals in raw.items():\n",
    "            date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "\n",
    "            if asset_type == \"crypto\":\n",
    "                row = {\n",
    "                    \"date\": date,\n",
    "                    \"open\": float(vals[\"1. open\"]),\n",
    "                    \"high\": float(vals[\"2. high\"]),\n",
    "                    \"low\": float(vals[\"3. low\"]),\n",
    "                    \"close\": float(vals[\"4. close\"]),\n",
    "                    \"volume\": float(vals[\"5. volume\"])\n",
    "                }\n",
    "            elif asset_type == \"fx\":\n",
    "                row = {\n",
    "                    \"date\": date,\n",
    "                    \"open\": float(vals[\"1. open\"]),\n",
    "                    \"high\": float(vals[\"2. high\"]),\n",
    "                    \"low\": float(vals[\"3. low\"]),\n",
    "                    \"close\": float(vals[\"4. close\"]),\n",
    "                    \"volume\": float(\"0\")  # FX has no volume\n",
    "                }\n",
    "            else:\n",
    "                row = {\n",
    "                    \"date\": date,\n",
    "                    \"open\": float(vals[\"1. open\"]),\n",
    "                    \"high\": float(vals[\"2. high\"]),\n",
    "                    \"low\": float(vals[\"3. low\"]),\n",
    "                    \"close\": float(vals[\"4. close\"]),\n",
    "                    \"volume\": float(vals.get(\"6. volume\", 0))\n",
    "                }\n",
    "\n",
    "            row[\"symbol\"] = symbol\n",
    "            row[\"source\"] = \"alpha_vantage\"\n",
    "            records.append(row)\n",
    "\n",
    "        df = pd.DataFrame(records)\n",
    "        df.sort_values(\"date\", inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def _fetch_yfinance(self, symbol: str):\n",
    "        try:\n",
    "            df = yf.download(symbol, period=\"max\", interval=\"1d\")\n",
    "            if df.empty:\n",
    "                return None\n",
    "\n",
    "            df = df.rename(columns={\n",
    "                \"Open\": \"open\",\n",
    "                \"High\": \"high\",\n",
    "                \"Low\": \"low\",\n",
    "                \"Close\": \"close\",\n",
    "                \"Volume\": \"volume\"\n",
    "            })\n",
    "            df[\"date\"] = df.index\n",
    "            df[\"symbol\"] = symbol\n",
    "            df[\"source\"] = \"yfinance\"\n",
    "            df = df.reset_index(drop=True)\n",
    "            return df\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def fetch(self, symbol: str, asset_type: str = \"stock\"):\n",
    "        # 1. Local CSV\n",
    "        local_df = self._load_local_csv(symbol)\n",
    "        if local_df is not None:\n",
    "            return local_df\n",
    "\n",
    "        # 2. Alpha Vantage\n",
    "        data = self._fetch_alpha_vantage(symbol, asset_type)\n",
    "        if data:\n",
    "            print(\"Alpha Vantage data fetched.\")\n",
    "            df = self._parse_alpha_vantage(data, symbol, asset_type)\n",
    "            if df is not None:\n",
    "                self._save_csv(df, symbol)\n",
    "                return df\n",
    "\n",
    "        # 3. yfinance fallback\n",
    "        df = self._fetch_yfinance(symbol)\n",
    "        if df is not None:\n",
    "            self._save_csv(df, symbol)\n",
    "            return df\n",
    "\n",
    "        return None\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "3751c2ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T01:47:33.044639Z",
     "start_time": "2026-01-03T01:47:33.042389Z"
    }
   },
   "source": [
    "# data/ingest.py\n",
    "# from .alphavantage import AlphaVantagePriceFetcher\n",
    "# Dependency Inversion to bulk download for different assets\n",
    "\n",
    "def ingest_price(symbol: str, asset_type: str = \"stock\"):\n",
    "    fetcher = AlphaVantagePriceFetcher()\n",
    "    df = fetcher.fetch(symbol, asset_type)\n",
    "    return df\n",
    "\n",
    "def batch_ingest(symbols: list, asset_type=\"stock\"):\n",
    "    results = {}\n",
    "    for s in symbols:\n",
    "        results[s] = ingest_price(s, asset_type)\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "5fd9d7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T01:47:33.083038Z",
     "start_time": "2026-01-03T01:47:33.052827Z"
    }
   },
   "source": [
    "print(load_dotenv(dotenv_path=\"../../config.env\"))  # Load environment variables from .env file if present\n",
    "fetcher = AlphaVantagePriceFetcher()\n",
    "symbol = \"BTC\"\n",
    "df = fetcher.fetch(symbol, asset_type=\"crypto\")\n",
    "print(df.info())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5627 entries, 0 to 5626\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    5627 non-null   datetime64[ns]\n",
      " 1   open    5627 non-null   float64       \n",
      " 2   high    5627 non-null   float64       \n",
      " 3   low     5627 non-null   float64       \n",
      " 4   close   5627 non-null   float64       \n",
      " 5   volume  5627 non-null   float64       \n",
      " 6   symbol  5627 non-null   object        \n",
      " 7   source  5627 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(5), object(2)\n",
      "memory usage: 351.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "f0e1a727",
   "metadata": {},
   "source": [
    "## Fetching several economic indicators "
   ]
  },
  {
   "cell_type": "code",
   "id": "9cc70c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T01:47:33.098737Z",
     "start_time": "2026-01-03T01:47:33.088660Z"
    }
   },
   "source": [
    "# data/econ_indicators.py\n",
    "ECON_DIR = \"../econ\"\n",
    "os.makedirs(ECON_DIR, exist_ok=True)\n",
    "\n",
    "class EconIndicatorsFetcher:\n",
    "    \"\"\"\n",
    "    Fetchers economic indicators: \n",
    "        - Fed Funds Rate\n",
    "        - CPI \n",
    "        - PPI \n",
    "        - Unemployment Rate\n",
    "        ....\n",
    "    Sources:\n",
    "        - Local CSVs\n",
    "        - FRED API\n",
    "        - Alpha Vantage macro endpoints\n",
    "    \"\"\"\n",
    "    FRED_URL = \"https://api.stlouisfed.org/fred/series/observations\"\n",
    "    \n",
    "    def __init__(self, fred_key_env=\"FRED_API_KEY\", alpha_key_env=\"ALPHAVANTAGE_API_KEY\"):\n",
    "        self.fred_key = os.environ.get(fred_key_env, None)\n",
    "        print(self.fred_key)\n",
    "        self.alpha_key = os.environ.get(alpha_key_env, None)\n",
    "        print(self.alpha_key)\n",
    "        \n",
    "    def _local_csv(self, name):\n",
    "        path = f\"{ECON_DIR}/{name}.csv\"\n",
    "        if os.path.exists(path):\n",
    "            return pd.read_csv(path, parse_dates=[\"date\"])\n",
    "        return None\n",
    "    \n",
    "    def _save_csv(self, df, name):\n",
    "        df.to_csv(f\"{ECON_DIR}/{name}.csv\", index=False)\n",
    "        \n",
    "    def _fetch_fred(self, series_id: str, start_date: str = None):\n",
    "        \"\"\"\n",
    "        Fetch from FRED API \n",
    "        Args:\n",
    "            series_id (str): type of data we fetch\n",
    "            start_date (str): YYYY-MM-DD string to start observations from (inclusive).\n",
    "        \"\"\"\n",
    "        if not self.fred_key:\n",
    "            return None\n",
    "        params = {\n",
    "            \"series_id\": series_id,\n",
    "            \"api_key\": self.fred_key,\n",
    "            \"file_type\": \"json\"\n",
    "            #\"observation_start\": \"1900-01-01\"\n",
    "        }\n",
    "        if start_date:\n",
    "            params[\"observation_start\"] = start_date\n",
    "        r = requests.get(self.FRED_URL, params=params)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        data = r.json()\n",
    "        if \"observations\" not in data:\n",
    "            return None\n",
    "        rows = []\n",
    "        for obs in data[\"observations\"]:\n",
    "            date = obs[\"date\"]\n",
    "            val = obs[\"value\"]\n",
    "            try:\n",
    "                val = float(val)\n",
    "            except:\n",
    "                continue\n",
    "            rows.append({\"date\": pd.to_datetime(date), \"value\": val})\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.sort_values(\"date\", inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def _ffill_daily(self, df, start,end):\n",
    "        \"\"\"\n",
    "        Convert to daily, then forward fill\n",
    "\n",
    "        Args:\n",
    "            df (_type_): _description_\n",
    "            start (_type_): _description_\n",
    "            end (_type_): _description_\n",
    "        \"\"\"\n",
    "        daily = pd.DataFrame({\"date\": pd.date_range(start=start, end=end, freq=\"D\")})\n",
    "        merged = pd.merge(daily, df, on=\"date\", how=\"left\")\n",
    "        merged[\"value\"] = merged[\"value\"].ffill()\n",
    "        return merged\n",
    "    \n",
    "    def fetch_indicator(self, name:str, fred_series: str):\n",
    "        \"\"\"\n",
    "        General Indicator fetcher with fallback and incremental update logic.\n",
    "        \"\"\"\n",
    "        local_df = self._local_csv(name)\n",
    "        \n",
    "        start_date = None\n",
    "        \n",
    "        # --- check existing csv and Incremental Update Logic ---\n",
    "        if local_df is not None and not local_df.empty:\n",
    "            last_date = local_df[\"date\"].max()\n",
    "            # Request data starting from the day *after* the last recorded date\n",
    "            start_date = (last_date + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "            print(f\"[{name}] Found local data up to {last_date.strftime('%Y-%m-%d')}. Fetching new data from {start_date}.\")\n",
    "        \n",
    "        # --- Fetch from FRED API ---\n",
    "        # Pass the calculated start_date (which is None if no local data, or the next day)\n",
    "        new_df = self._fetch_fred(fred_series, start_date=start_date)\n",
    "\n",
    "        if new_df is not None and not new_df.empty:\n",
    "            \n",
    "            if local_df is not None and not local_df.empty:\n",
    "                # Merge the local data and the new data\n",
    "                combined_df = pd.concat([local_df, new_df], ignore_index=True)\n",
    "                # Ensure no duplicates just in case\n",
    "                combined_df = combined_df.drop_duplicates(subset=['date'], keep='last')\n",
    "                print(f\"[{name}] Updated with {len(new_df)} new observations.\")\n",
    "            else:\n",
    "                # First fetch\n",
    "                combined_df = new_df\n",
    "                print(f\"[{name}] Initial fetch of {len(new_df)} observations.\")\n",
    "            \n",
    "            combined_df.sort_values(\"date\", inplace=True)\n",
    "            self._save_csv(combined_df, name)\n",
    "            return combined_df\n",
    "        \n",
    "        # --- Return existing local data if no new data was fetched ---\n",
    "        if local_df is not None:\n",
    "            print(f\"[{name}] No new data found. Returning existing local data.\")\n",
    "            return local_df\n",
    "        \n",
    "        # --- Fallback: empty CSV for compatibility (if no local and no fetch) ---\n",
    "        print(f\"[{name}] Failed to fetch and no local data found.\")\n",
    "        empty = pd.DataFrame({\"date\": [], \"value\": []})\n",
    "        self._save_csv(empty, name)\n",
    "        return empty\n",
    "    \n",
    "    def fetch_all(self):\n",
    "        indicators = {\n",
    "        # CORE INTEREST & LABOR\n",
    "        \"fed_funds_rate\": \"FEDFUNDS\",\n",
    "        \"unemployment_rate\": \"UNRATE\",\n",
    "        \"nonfarm_payrolls\": \"PAYEMS\",       # All Employees, Total Nonfarm (Thousands of Persons)\n",
    "\n",
    "        # PRICE INDICES\n",
    "        \"cpi\": \"CPIAUCSL\",                  # Consumer Price Index for All Urban Consumers: All Items (Seasonally Adjusted)\n",
    "        \"ppi\": \"PPIACO\",                    # Producer Price Index: All Commodities (Not Seasonally Adjusted)\n",
    "        \n",
    "        # GROWTH & SPENDING (Quarterly/Monthly)\n",
    "        \"gdp\": \"GDPC1\",                     # Real Gross Domestic Product (Quarterly, Billions of Chained 2017 Dollars)\n",
    "        \"retail_sales\": \"RSXFS\",            # Advance Retail Sales: Retail Trade (Monthly, Seasonally Adjusted)\n",
    "        \"industrial_production\": \"INDPRO\",  # Industrial Production Index (Monthly)\n",
    "        \"building_permits\": \"PERMIT\",       # New Private Housing Units Authorized by Building Permits (Monthly)\n",
    "        \n",
    "        # SENTIMENT & TRADE\n",
    "        \"consumer_confidence\": \"UMCSENT\",   # University of Michigan: Consumer Sentiment (Monthly)\n",
    "        \"trade_balance\": \"NETEXC\",          # Net Exports of Goods and Services (Quarterly, Billions of Dollars)\n",
    "        \n",
    "        # MONEY SUPPLY (M3 is discontinued, M1/M2 are standard)\n",
    "        \"money_supply_m1\": \"M1SL\",          # M1 Money Stock (Monthly)\n",
    "        \"money_supply_m2\": \"M2SL\",          # M2 Money Stock (Monthly)\n",
    "        \n",
    "        # INFLATION (often calculated, but PCE is an alternative index)\n",
    "        \"pce_inflation\": \"PCEPI\",           # Personal Consumption Expenditures Price Index (Monthly)\n",
    "        }\n",
    "        out = {}\n",
    "        for name, series_id in indicators.items():\n",
    "            df = self.fetch_indicator(name, series_id)\n",
    "            out[name] = df\n",
    "        return out\n",
    "    \n",
    "    def generate_daily_econ(self, start=\"2000-01-01\", end=None):\n",
    "        \"\"\"\n",
    "        Produces daily versions of all indicators.\n",
    "        \"\"\"\n",
    "        if end is None:\n",
    "            end = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        raw = self.fetch_all()\n",
    "        daily_frames = []\n",
    "\n",
    "        for name, df in raw.items():\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            ddf = self._ffill_daily(df, start, end)\n",
    "            ddf[\"indicator\"] = name\n",
    "            daily_frames.append(ddf)\n",
    "\n",
    "        if not daily_frames:\n",
    "            return None\n",
    "\n",
    "        long_df = (\n",
    "            pd.concat(daily_frames, axis=0)\n",
    "            .sort_values(\"date\")\n",
    "        )\n",
    "\n",
    "        wide_df = (\n",
    "            long_df\n",
    "            .pivot(index=\"date\", columns=\"indicator\", values=\"value\")\n",
    "            .sort_index()\n",
    "            .ffill()\n",
    "        )\n",
    "\n",
    "        out_path = f\"{ECON_DIR}/econ_wide_daily.csv\"\n",
    "        wide_df.to_csv(out_path)\n",
    "\n",
    "        return wide_df"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "9af8a49a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T01:47:33.233501Z",
     "start_time": "2026-01-03T01:47:33.104701Z"
    }
   },
   "source": [
    "print(load_dotenv(dotenv_path=\"../../config.env\"))  # Load environment variables from .env file if present\n",
    "econ = EconIndicatorsFetcher()\n",
    "df = econ.fetch_all()\n",
    "df = econ.generate_daily_econ(start=\"2000-01-01\")  # replace the start date with the start of the price dataset from above\n",
    "print(df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "None\n",
      "[fed_funds_rate] Found local data up to 2025-11-01. Fetching new data from 2025-11-02.\n",
      "[fed_funds_rate] No new data found. Returning existing local data.\n",
      "[unemployment_rate] Found local data up to 2025-11-01. Fetching new data from 2025-11-02.\n",
      "[unemployment_rate] No new data found. Returning existing local data.\n",
      "[nonfarm_payrolls] Found local data up to 2025-11-01. Fetching new data from 2025-11-02.\n",
      "[nonfarm_payrolls] No new data found. Returning existing local data.\n",
      "[cpi] Found local data up to 2025-09-01. Fetching new data from 2025-09-02.\n",
      "[cpi] No new data found. Returning existing local data.\n",
      "[ppi] Found local data up to 2025-09-01. Fetching new data from 2025-09-02.\n",
      "[ppi] No new data found. Returning existing local data.\n",
      "[gdp] Found local data up to 2025-04-01. Fetching new data from 2025-04-02.\n",
      "[gdp] No new data found. Returning existing local data.\n",
      "[retail_sales] Found local data up to 2025-10-01. Fetching new data from 2025-10-02.\n",
      "[retail_sales] No new data found. Returning existing local data.\n",
      "[industrial_production] Found local data up to 2025-09-01. Fetching new data from 2025-09-02.\n",
      "[industrial_production] No new data found. Returning existing local data.\n",
      "[building_permits] Found local data up to 2025-08-01. Fetching new data from 2025-08-02.\n",
      "[building_permits] No new data found. Returning existing local data.\n",
      "[consumer_confidence] Found local data up to 2025-10-01. Fetching new data from 2025-10-02.\n",
      "[consumer_confidence] No new data found. Returning existing local data.\n",
      "[trade_balance] Found local data up to 2025-04-01. Fetching new data from 2025-04-02.\n",
      "[trade_balance] No new data found. Returning existing local data.\n",
      "[money_supply_m1] Found local data up to 2025-10-01. Fetching new data from 2025-10-02.\n",
      "[money_supply_m1] No new data found. Returning existing local data.\n",
      "[money_supply_m2] Found local data up to 2025-10-01. Fetching new data from 2025-10-02.\n",
      "[money_supply_m2] No new data found. Returning existing local data.\n",
      "[pce_inflation] Found local data up to 2025-09-01. Fetching new data from 2025-09-02.\n",
      "[pce_inflation] No new data found. Returning existing local data.\n",
      "[fed_funds_rate] Found local data up to 2025-11-01. Fetching new data from 2025-11-02.\n",
      "[fed_funds_rate] No new data found. Returning existing local data.\n",
      "[unemployment_rate] Found local data up to 2025-11-01. Fetching new data from 2025-11-02.\n",
      "[unemployment_rate] No new data found. Returning existing local data.\n",
      "[nonfarm_payrolls] Found local data up to 2025-11-01. Fetching new data from 2025-11-02.\n",
      "[nonfarm_payrolls] No new data found. Returning existing local data.\n",
      "[cpi] Found local data up to 2025-09-01. Fetching new data from 2025-09-02.\n",
      "[cpi] No new data found. Returning existing local data.\n",
      "[ppi] Found local data up to 2025-09-01. Fetching new data from 2025-09-02.\n",
      "[ppi] No new data found. Returning existing local data.\n",
      "[gdp] Found local data up to 2025-04-01. Fetching new data from 2025-04-02.\n",
      "[gdp] No new data found. Returning existing local data.\n",
      "[retail_sales] Found local data up to 2025-10-01. Fetching new data from 2025-10-02.\n",
      "[retail_sales] No new data found. Returning existing local data.\n",
      "[industrial_production] Found local data up to 2025-09-01. Fetching new data from 2025-09-02.\n",
      "[industrial_production] No new data found. Returning existing local data.\n",
      "[building_permits] Found local data up to 2025-08-01. Fetching new data from 2025-08-02.\n",
      "[building_permits] No new data found. Returning existing local data.\n",
      "[consumer_confidence] Found local data up to 2025-10-01. Fetching new data from 2025-10-02.\n",
      "[consumer_confidence] No new data found. Returning existing local data.\n",
      "[trade_balance] Found local data up to 2025-04-01. Fetching new data from 2025-04-02.\n",
      "[trade_balance] No new data found. Returning existing local data.\n",
      "[money_supply_m1] Found local data up to 2025-10-01. Fetching new data from 2025-10-02.\n",
      "[money_supply_m1] No new data found. Returning existing local data.\n",
      "[money_supply_m2] Found local data up to 2025-10-01. Fetching new data from 2025-10-02.\n",
      "[money_supply_m2] No new data found. Returning existing local data.\n",
      "[pce_inflation] Found local data up to 2025-09-01. Fetching new data from 2025-09-02.\n",
      "[pce_inflation] No new data found. Returning existing local data.\n",
      "indicator   building_permits  consumer_confidence      cpi  fed_funds_rate  \\\n",
      "date                                                                         \n",
      "2000-01-01            1727.0                112.0  169.300            5.45   \n",
      "2000-01-02            1727.0                112.0  169.300            5.45   \n",
      "2000-01-03            1727.0                112.0  169.300            5.45   \n",
      "2000-01-04            1727.0                112.0  169.300            5.45   \n",
      "2000-01-05            1727.0                112.0  169.300            5.45   \n",
      "...                      ...                  ...      ...             ...   \n",
      "2025-12-30            1330.0                 53.6  324.368            3.88   \n",
      "2025-12-31            1330.0                 53.6  324.368            3.88   \n",
      "2026-01-01            1330.0                 53.6  324.368            3.88   \n",
      "2026-01-02            1330.0                 53.6  324.368            3.88   \n",
      "2026-01-03            1330.0                 53.6  324.368            3.88   \n",
      "\n",
      "indicator         gdp  industrial_production  money_supply_m1  \\\n",
      "date                                                            \n",
      "2000-01-01  13878.147                91.5380           1122.1   \n",
      "2000-01-02  13878.147                91.5380           1122.1   \n",
      "2000-01-03  13878.147                91.5380           1122.1   \n",
      "2000-01-04  13878.147                91.5380           1122.1   \n",
      "2000-01-05  13878.147                91.5380           1122.1   \n",
      "...               ...                    ...              ...   \n",
      "2025-12-30  23770.976               101.4279          19004.2   \n",
      "2025-12-31  23770.976               101.4279          19004.2   \n",
      "2026-01-01  23770.976               101.4279          19004.2   \n",
      "2026-01-02  23770.976               101.4279          19004.2   \n",
      "2026-01-03  23770.976               101.4279          19004.2   \n",
      "\n",
      "indicator   money_supply_m2  nonfarm_payrolls  pce_inflation      ppi  \\\n",
      "date                                                                    \n",
      "2000-01-01           4667.6          131011.0         72.961  128.300   \n",
      "2000-01-02           4667.6          131011.0         72.961  128.300   \n",
      "2000-01-03           4667.6          131011.0         72.961  128.300   \n",
      "2000-01-04           4667.6          131011.0         72.961  128.300   \n",
      "2000-01-05           4667.6          131011.0         72.961  128.300   \n",
      "...                     ...               ...            ...      ...   \n",
      "2025-12-30          22298.1          159552.0        127.625  262.344   \n",
      "2025-12-31          22298.1          159552.0        127.625  262.344   \n",
      "2026-01-01          22298.1          159552.0        127.625  262.344   \n",
      "2026-01-02          22298.1          159552.0        127.625  262.344   \n",
      "2026-01-03          22298.1          159552.0        127.625  262.344   \n",
      "\n",
      "indicator   retail_sales  trade_balance  unemployment_rate  \n",
      "date                                                        \n",
      "2000-01-01      237541.0       -380.953                4.0  \n",
      "2000-01-02      237541.0       -380.953                4.0  \n",
      "2000-01-03      237541.0       -380.953                4.0  \n",
      "2000-01-04      237541.0       -380.953                4.0  \n",
      "2000-01-05      237541.0       -380.953                4.0  \n",
      "...                  ...            ...                ...  \n",
      "2025-12-30      633232.0      -1058.037                4.6  \n",
      "2025-12-31      633232.0      -1058.037                4.6  \n",
      "2026-01-01      633232.0      -1058.037                4.6  \n",
      "2026-01-02      633232.0      -1058.037                4.6  \n",
      "2026-01-03      633232.0      -1058.037                4.6  \n",
      "\n",
      "[9500 rows x 14 columns]\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
